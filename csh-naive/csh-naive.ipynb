{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitd971ed7fa96a4d68952e347dc9ad6f21",
   "display_name": "Python 3.7.3 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hadamard(n):\n",
    "    if n == 1:\n",
    "        return np.ones((1,1), dtype=np.int32)\n",
    "    else:\n",
    "        a = hadamard(n//2)\n",
    "        b = np.ones((n,n), dtype=np.int32)\n",
    "        sign = 1\n",
    "        for i in np.arange(0,n):\n",
    "            if i % 2:\n",
    "                sign *= -1\n",
    "            b[i,:n//2] = a[i % n//2]\n",
    "            b[i,n//2:] = sign*a[i % n//2]\n",
    "        return b\n",
    "    \n",
    "def hadamard_2d(n):\n",
    "    a = hadamard(n)\n",
    "    return np.array([np.outer(x,y) for x in a for y in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_used_small = [0,1,9,8] #As used in the article\n",
    "kernels_used_large = [0,1,2,3,4,8,9,10,11,16,17,18,24,25,32] #As used in the article: TODO find a smarter way of doing this\n",
    "#Results in a lot of copy paste\n",
    "def apply_wh_kernels(img, size=8):\n",
    "    kernels = hadamard_2d(size) \n",
    "    #kernels used is only specified for size 8 for now.\n",
    "    (x,y) = (img.shape[0] + 1 - size, img.shape[1] + 1 - size)\n",
    "    y_kerns = np.ones((x,y,len(kernels_used_large)),dtype=np.int32)\n",
    "    cb_kerns = np.ones((x,y,len(kernels_used_small)),dtype=np.int32)\n",
    "    cr_kerns = np.ones((x,y,len(kernels_used_small)),dtype=np.int32)\n",
    "    for i in np.arange(0, len(kernels_used_large)):\n",
    "        y_kerns[:,:,i] = signal.convolve2d(img[:,:,0], kernels[kernels_used_large[i]], mode='valid')\n",
    "    for i in np.arange(0, len(kernels_used_small)):\n",
    "        cb_kerns[:,:,i] = signal.convolve2d(img[:,:,1], kernels[kernels_used_small[i]], mode='valid')\n",
    "    for i in np.arange(0, len(kernels_used_small)): #might've swapped cb and cr namewise, but their use is identical/symmetrical later on, so it doesn't matter\n",
    "        cr_kerns[:,:,i] = signal.convolve2d(img[:,:,2], kernels[kernels_used_small[i]], mode='valid')\n",
    "    return (y_kerns, cb_kerns, cr_kerns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_values(img_a, img_b, bin_count, offset):\n",
    "    #How this is handled is defined vaguely in the article\n",
    "    rnd_nr = rand.random()\n",
    "    quant_offset = rnd_nr/bin_count\n",
    "    quants = [x/bin_count + quant_offset for x in np.arange(1,bin_count)]\n",
    "    quants[bin_count-2] = 1\n",
    "    borders = np.quantile(img_a, quants,interpolation='higher')\n",
    "    return ((rnd_nr*bin_count+np.digitize(img_a, borders)) % bin_count).astype(int)<<offset, ((rnd_nr*bin_count+np.digitize(img_b, borders)) % bin_count).astype(int)<<offset\n",
    "    #return borders\n",
    "\n",
    "\n",
    "def create_hash_tables(img_a, img_b, L = 4, k = 2):\n",
    "    (x1,y1) = (img_a[0].shape[0],img_a[0].shape[1])\n",
    "    (x2,y2) = (img_b[0].shape[0],img_b[0].shape[1])\n",
    "    hash_a = np.zeros((L,x1,y1),dtype = np.int64)\n",
    "    hash_b = np.zeros((L,x2,y2),dtype = np.int64)\n",
    "    hash_table_a = np.zeros((L,2**18,k,2),dtype = np.int64) - 1 #18 bits\n",
    "    hash_table_b = np.zeros((L,2**18,k,2),dtype = np.int64) - 1 #Should've just flattened everything TODO\n",
    "    #rand.random()\n",
    "    magic_kernel = [0, 0, 0, 1, 5, 6, 2, 9] # kernel used\n",
    "    magic_data = [0, 1, 2, 0, 0, 0, 0, 0] # colour/intensity used\n",
    "    magic_bits = [5, 2, 2, 3, 3, 1, 1, 1] # number of bits for the current kernel\n",
    "    #same numbers as used in article\n",
    "    for i in np.arange(L):\n",
    "        offset = 0\n",
    "        for j in np.arange(0, 8):\n",
    "            bins = 2**magic_bits[j]\n",
    "            (cur_bins_a, cur_bins_b) = bin_values(img_a[magic_data[j]][:,:,magic_kernel[j]], img_b[magic_data[j]][:,:,magic_kernel[j]], bins, offset)\n",
    "            hash_a[i,:,:] += cur_bins_a\n",
    "            hash_b[i,:,:] += cur_bins_b\n",
    "            offset+=magic_bits[j]\n",
    "    print(\"Computed hashes\")    \n",
    "    #hash_tables\n",
    "    for i in np.arange(L):\n",
    "        for j in np.arange(x1):\n",
    "            for m in np.arange(y1):\n",
    "                cur_hash = hash_a[i,j,m]\n",
    "                for n in np.arange(k):\n",
    "                    if hash_table_a[i,cur_hash, n, 0] < 0:\n",
    "                        hash_table_a[i,cur_hash, n, 0] = j\n",
    "                        hash_table_a[i,cur_hash, n, 1] = m\n",
    "                        break\n",
    "    print(\"Computed hash tables for first image\")\n",
    "    for i in np.arange(L):\n",
    "        for j in np.arange(x2):\n",
    "            for m in np.arange(y2):\n",
    "                cur_hash = hash_b[i,j,m]\n",
    "                for n in np.arange(k):\n",
    "                    if hash_table_b[i,cur_hash, n, 0] < 0:\n",
    "                        hash_table_b[i,cur_hash, n, 0] = j\n",
    "                        hash_table_b[i,cur_hash, n, 1] = m\n",
    "                        break\n",
    "    print(\"Computed hash tables for second image\")\n",
    "    return hash_a, hash_b, hash_table_a, hash_table_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_matches(x1, y1,x2, y2):\n",
    "    xs = (np.random.rand(x1,y1)*x2).astype(int)\n",
    "    ys = (np.random.rand(x1,y1)*y2).astype(int)\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidates_hash_match(hash_a, hash_table_b):\n",
    "    return hash_table_b[hash_a,:,:]\n",
    "\n",
    "def find_candidates_neighbours(hash_b, hash_table_b, cur_matches, x2, y2):\n",
    "    left1,left2 = (cur_matches[0][:-1,:]+1, cur_matches[1][:-1,:])\n",
    "    left1[left1==x2] = 0 # bad candidate, but current candidate is outside the patches\n",
    "    left = hash_table_b[hash_b[(left1,left2)]]\n",
    "    left = np.concatenate((np.zeros((1,y2,2,2),dtype=np.int64)-1,left))\n",
    "\n",
    "    right1,right2 = (cur_matches[0][1:,:]-1, cur_matches[1][1:,:])\n",
    "    right1[right1==0] = 0 # bad candidate, but current candidate is outside the patches\n",
    "    right = hash_table_b[hash_b[(right1,right2)]]\n",
    "    right = np.concatenate((right,np.zeros((1,y2,2,2),dtype=np.int64)-1))\n",
    "\n",
    "    up1,up2 = (cur_matches[0][:,:-1], cur_matches[1][:,:-1]+1)\n",
    "    up2[up2==y2] = 0 # bad candidate, but current candidate is outside the patches\n",
    "    up = hash_table_b[hash_b[(up1,up2)]]\n",
    "    up = np.concatenate((np.zeros((x2,1,2,2), dtype=np.int64)-1,up),axis=1)\n",
    "\n",
    "    down1,down2 = (cur_matches[0][:,1:], cur_matches[1][:,1:]-1)\n",
    "    down2[down2==0] = 0 # bad candidate, but current candidate is outside the patches\n",
    "    down = hash_table_b[hash_b[(down1,down2)]]\n",
    "    down = np.concatenate((down,np.zeros((x2,1,2,2), dtype=np.int64)-1),axis=1)\n",
    "\n",
    "    return np.concatenate((left,right, up, down),axis=2)\n",
    "\n",
    "def find_candidates_match_match(hash_a, hash_table_a, cur_matches):\n",
    "    similar_patches = hash_table_a[hash_a,:,:]\n",
    "    similar_patches[similar_patches[:,:,0] < 0] = 0\n",
    "    return np.stack((cur_matches[0][similar_patches[:,:,:,0],similar_patches[:,:,:,1]],cur_matches[1][similar_patches[:,:,:,0],similar_patches[:,:,:,1]]),axis=3)\n",
    "    #return similar_patches\n",
    "\n",
    "def find_candidates(hash_a, hash_b, hash_table_a, hash_table_b, cur_matches, x2, y2):\n",
    "    first_set = find_candidates_hash_match(hash_a, hash_table_b)\n",
    "    second_set = find_candidates_neighbours(hash_b, hash_table_b, cur_matches, x2, y2)\n",
    "    third_set = find_candidates_match_match(hash_a, hash_table_a, cur_matches)\n",
    "    return np.concatenate((first_set, second_set, third_set),axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(candidates, kernels_a, kernels_b, x1, y1, cur_matches):\n",
    "    diffs = np.zeros((x1,y1))\n",
    "    diffs = np.linalg.norm(kernels_b-kernels_a, axis=2)\n",
    "    cur_kernels = kernels_b[candidates[:,:,:,0], candidates[:,:,:,1]]\n",
    "    cur_diffs = np.linalg.norm(cur_kernels-kernels_a[:,:,np.newaxis,:],axis=3)\n",
    "    for i in np.arange(x1):\n",
    "        for j in np.arange(y1):\n",
    "            best = np.argmin(cur_diffs[i,j,:])\n",
    "            if diffs[i,j] > cur_diffs[i,j,best]:\n",
    "                cur_matches[0][i,j] = candidates[i,j,best,0]    \n",
    "                cur_matches[1][i,j] = candidates[i,j,best,1]    \n",
    "    return cur_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(hashes, kernels_a, kernels_b):\n",
    "    hash_a = hashes[0]\n",
    "    kernels_a = np.concatenate((kernels_a),axis=2)\n",
    "    kernels_b = np.concatenate((kernels_b),axis=2)\n",
    "    hash_b = hashes[1]\n",
    "    hash_table_a = hashes[2]\n",
    "    hash_table_b = hashes[3]\n",
    "    L,x1,y1 = hash_a.shape[0], hash_a.shape[1],hash_a.shape[2]\n",
    "    x2,y2 = hash_b.shape[1],hash_b.shape[2]\n",
    "    cur_matches = init_matches(x1, y1, x2, y2)\n",
    "    #L = 4\n",
    "    for i in np.arange(L):\n",
    "        print(\"Starting iteration {}\".format(i))\n",
    "        cur_candidates = find_candidates(hash_a[i,:,:], hash_b[i,:,:], hash_table_a[i,:,:,:], hash_table_b[i,:,:,:], cur_matches, x2, y2)\n",
    "        cur_matches = find_best(cur_candidates, kernels_a, kernels_b, x1, y1, cur_matches)\n",
    "    return cur_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_a = cv2.imread(\"data/example/1.jpg\")\n",
    "image_b = cv2.imread(\"data/example/2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_a2 = cv2.cvtColor(image_a, cv2.COLOR_BGR2YCR_CB).astype(int)\n",
    "#image_b2 = cv2.cvtColor(image_b, cv2.COLOR_BGR2YCR_CB).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step indexing of CSH\n",
    "image_a3 = apply_wh_kernels(image_a2)\n",
    "#image_b3 = apply_wh_kernels(image_b2)"
   ]
  },
  {
   "source": [
    "#step hashing of CSH\n",
    "#hashes = create_hash_tables(image_a3, image_b3)\n",
    "hashes = create_hash_tables(image_a3, image_a3)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computed hashes\n",
      "Computed hash tables for first image\n",
      "Computed hash tables for second image\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting iteration 0\n",
      "Starting iteration 1\n",
      "Starting iteration 2\n",
      "Starting iteration 3\n"
     ]
    }
   ],
   "source": [
    "test = fit(hashes, image_a3, image_a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(793, 1913)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('patches-self.npy', 'wb') as f:\n",
    "    np.save(f, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('patches-self.npy', 'rb') as f:\n",
    "    a= np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_error(matches, orig_img, trg_img, patch_size):\n",
    "    #RMS\n",
    "    errs = np.zeros_like(matches[0])\n",
    "    x,y,z = orig_img.shape\n",
    "    xs, ys = matches\n",
    "    for i in np.arange(0,patch_size):\n",
    "        for j in np.arange(0,patch_size):\n",
    "            errs+= np.sum((orig_img[i:x+i-patch_size+1, j:y+j-patch_size+1,:]-trg_img[xs+i,ys+j,:])**2,axis=2)\n",
    "    \n",
    "    return np.mean(errs/patch_size**2/3)**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = mean_error(a, image_a, image_a, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}